{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fffaeac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joonryu/.pyenv/versions/cb_stream/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Fetching 6 files: 100%|██████████| 6/6 [00:00<00:00, 114390.11it/s]\n",
      "/home/joonryu/.pyenv/versions/cb_stream/lib/python3.11/site-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.\n",
      "  deprecate(\"LoRACompatibleLinear\", \"1.0.0\", deprecation_message)\n",
      "WARNING:chatterbox.models.tokenizers.tokenizer:pkuseg not available - Chinese segmentation will be skipped\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded PerthNet (Implicit) at step 250,000\n"
     ]
    }
   ],
   "source": [
    "import torchaudio as ta\n",
    "import torch\n",
    "#from chatterbox.tts import ChatterboxTTS\n",
    "from chatterbox.mtl_tts import ChatterboxMultilingualTTS\n",
    "\n",
    "model = ChatterboxMultilingualTTS.from_pretrained(device=\"cuda\")\n",
    "AUDIO_PROMPT_PATH = \"../jaemay_short.mp3\"\n",
    "#model.t3._step_compilation_target = torch.compile(model.t3._step_compilation_target, fullgraph=True, backend=\"cudagraphs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1319554a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latency to first chunk: 3.333s\n",
      "First chunk latency: 3.333s\n",
      "First chunk latency: 3.333s\n",
      "First chunk latency: 3.333s\n",
      "First chunk latency: 3.333s\n",
      "First chunk latency: 3.333s\n",
      "First chunk latency: 3.333s\n",
      "First chunk latency: 3.333s\n",
      "Total generation time: 25.437s\n",
      "Total audio duration: 28.682s\n",
      "RTF (Real-Time Factor): 0.887\n",
      "Total chunks yielded: 6\n"
     ]
    }
   ],
   "source": [
    "#text = \"This streaming synthesis will use a custom voice from the reference audio file.Lucid (NASDAǪ: LCID) is a Silicon Valley-based technology company focused on creating the most advanced EVs in the world. The award-winning Lucid Air and Lucid Gravity SUV deliver best-in-class performance, sophisticated design, expansive interior space and unrivaled energy efficiency. Lucid assembles both vehicles in its state-of-the-art, vertically integrated factories in Arizona and Saudi Arabia. Through its industry-leading technology and innovations, Lucid is advancing the state-of- the-art of EV technology for the benefit of all.\"\n",
    "#text = '우드 씨이오는 육일 현지시간 미 경제방송 씨엔비씨 인터뷰에서 장기적인 비트코인 가격 전망과 관련해 지난 몇 년간 우리 입장에서 달라진 한 가지를 말하자면, 비트코인이 맡을 거라고 생각했던 역할 일부를 스테이블코인이 빼앗고 있다는 것이라며 비트코인이 이천삼십년까지 백오십만달러, 약 이십일억칠천만원에 도달한다는 기존 전망이 달라질 수 있다고 밝혔다.'\n",
    "\n",
    "import torchaudio as ta\n",
    "import torch\n",
    "#from chatterbox.tts import ChatterboxTTS\n",
    "from chatterbox.mtl_tts import ChatterboxMultilingualTTS\n",
    "\n",
    "model = ChatterboxMultilingualTTS.from_pretrained(device=\"cuda\")\n",
    "AUDIO_PROMPT_PATH = None\n",
    "\n",
    "\n",
    "text = '이재명 대통령이 지난 대선에서 증명했듯, 우리는 하나일 때 가장 강하다고 말했습니다. 이 대통령은 오늘 십일 경기 광주시에서 열린 민주당 전국 지역위원장 워크숍에서 축사를 통해 이 같이 밝혔습니다. 강훈식 대통령실 비서실장이 대독한 축사에서 이 대통령은 집권여당의 무거운 책임을 함께 나누는 동지로서 또 오랜 동료로서 반가운 마음을 담아 인사드린다며 지역위원회와 시 도 당이라는 뿌리가 튼튼한 정당이어야 국민 행복의 열매를 맺고 민생 안정의 성과를 꽃피울 수 있다고 전했습니다.'\n",
    "\n",
    "\n",
    "audio_chunks = []\n",
    "for audio_chunk, metrics in model.generate_stream(\n",
    "    text, \n",
    "    audio_prompt_path=AUDIO_PROMPT_PATH,\n",
    "    exaggeration=2.5,\n",
    "    context_window=150,\n",
    "    fade_duration=0.035,\n",
    "    cfg_weight=0.000001,\n",
    "    chunk_size=120,  # Smaller chunks for lower latency\n",
    "    language_id='ko',\n",
    "    repetition_penalty=1.4,   #stable 40, 1.5\n",
    "    temperature=0.3,\n",
    "):\n",
    "    audio_chunks.append(audio_chunk)\n",
    "    \n",
    "    # Real-time metrics available\n",
    "    if metrics.latency_to_first_chunk:\n",
    "        print(f\"First chunk latency: {metrics.latency_to_first_chunk:.3f}s\")\n",
    "\n",
    "# Save the complete streaming output\n",
    "final_audio = torch.cat(audio_chunks, dim=-1)\n",
    "ta.save(\"output.wav\", final_audio, model.sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747b7866",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cb_api",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
